# English-French-Neural_Machine-Translator
 Engineered an end-to-end English-to-French translation system using a
 custom sequence-to-sequence (Seq2Seq) architecture enhanced with convolutional layers and attention mechanisms. Conducted
 thorough text preprocessing including normalization, tokenization, and padding of bilingual corpora. Designed two deep
 learning models: (1) a pure LSTM-based encoder-decoder and (2) a hybrid CNN-LSTM model with additive attention for
 improved contextual alignment. The CNN-LSTM-attention model achieved a superior corpus-level BLEU score of 95.07,
 outperforming the pure LSTM model, which attained a BLEU score of 91.82.
